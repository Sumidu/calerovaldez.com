<!DOCTYPE html>
<html>
  <head>
    <title>9 - Zusammenhänge, Korrelation, lineare Regression</title>
    <meta charset="utf-8">
    <meta name="author" content="Dr. André Calero Valdez Prof. Dr. Martina Ziefle    Human-Computer Interaction Center" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="hcic.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# 9 - Zusammenhänge, Korrelation, lineare Regression
## Sozialwissenschaftliche Forschungsmethoden für Fortgeschrittene
### <strong>Dr. André Calero Valdez</strong><br />Prof. Dr. Martina Ziefle <br /> <br />Human-Computer Interaction Center<br />
### Wintersemester 19/20

---





# Übersicht

1. .gray[Was sind Methoden?] =&gt; [Link](lecture01.html) `\(\checkmark\)`
2. .gray[Qualitative und Quantitative Daten? Forschungsfrage wählen] =&gt; [Link](lecture02.html) `\(\checkmark\)`
3. .gray[Wissenschaftstheorie, Empirie und Theorie] =&gt; [Link](lecture03.html) `\(\checkmark\)`
4. .gray[Forschungsintstrument entwickeln, Messtheorie, Skalenniveaus] =&gt; [Link](lecture04.html) `\(\checkmark\)`
5. .gray[Deskriptive Statistik, zentrale Tendenz und Streuung] =&gt; [Link](lecture05.html) `\(\checkmark\)`
6. .gray[Verteilungen, Stichproben und Wahrscheinlichkeit] =&gt; [Link](lecture06.html) `\(\checkmark\)`
7. .gray[Inferenz, Hypothesen, Fehler 1. und 2. Art, t-Test] =&gt; [Link](lecture07.html) `\(\checkmark\)`
8. .gray[Alpha-Fehler Kummulierung, ANOVA, MANOVA, Bonferroni] =&gt; [Link](lecture08.html)
9. **Zusammenhänge, Korrelation, lineare Regression** =&gt; [Link](lecture09.html)
10. Skalen, Likert-Skalen, Reliabilität und Faktoren-Analyse =&gt; [Link](lecture10.html)
11. Explorative Statistik, parametrische und nicht-parametrische Verfahren =&gt; [Link](lecture11.html)
12. Conjoint-Verfahren, Cluster-Analyse =&gt; [Link](lecture12.html)
13. Effekt-Stärken und Poweranalyse =&gt; [Link](lecture13.html)

---
# Wiederholung
![](figs/distributions.png)
---

# T-Test und Inferenz

- Was ist Inferenz? Schließen von Stichprobe auf Grundgesamtheit.

- NHST Test-Verfahren zum prüfen einer Hypothese. 
- Hypothesen ( `\(H_{0}\)` und `\(H_1\)` )
- Nur `\(H_0\)` kann verworfen werden.
- Signifikanz-Niveau `\(\alpha\)`
- Test-Statistik (t) und p-Wert prüfen.

- `\(\alpha\)`-Fehler und `\(\beta\)`-Fehler

3 Varianten t-Tests zum Prüfen von Unterschiedshypothesen
- einfacher t-Test, independent sample t-Test, paired sample t-Test

---

# Unterschiedshypothesen

&gt; Gibt es einen Unterschied zwischen...

##Der t-Test für
- 2 Gruppen (within oder between subjects)
- Normalverteilte abhängige Variable

## Mehrere Hypothesen
- Varianzanalyse (ANOVA)
- One-way oder two-way
- Mit oder ohne Covariate (ANCOVA)
- Mehrere Abhängige (MANCOVA)



---
# Univariate und Multivariate Statistik

.pull-left[
## Univariate

```
##    height
## 1   188.9
## 2   165.1
## 3   189.9
## 4   189.1
## 5   176.2
## 6   146.9
## 7   156.1
## 8   165.6
## 9   169.9
## 10  206.1
```

&lt;img src="lecture09_files/figure-html/unnamed-chunk-1-1.png" width="504" style="display: block; margin: auto;" /&gt;
]

--

.pull-right[
## Multivariate

```
##    height shoesize
## 1   188.9 40.69711
## 2   165.1 37.60505
## 3   189.9 37.31187
## 4   189.1 39.10078
## 5   176.2 37.61370
## 6   146.9 37.08701
## 7   156.1 39.11146
## 8   165.6 39.37670
## 9   169.9 36.77494
## 10  206.1 37.53821
```

&lt;img src="lecture09_files/figure-html/unnamed-chunk-2-1.png" width="504" style="display: block; margin: auto;" /&gt;
]

---
# Multivariate
&lt;img src="lecture09_files/figure-html/unnamed-chunk-3-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Zusammenhangshypothesen

&gt; Gibt es einen Zusammenhang zwischen... (je mehr, desto..)

&lt;img src="lecture09_files/figure-html/unnamed-chunk-4-1.png" width="504" style="display: block; margin: auto;" /&gt;
---
# Zusammenhangshypothesen

&gt; Gibt es einen Zusammenhang zwischen... (je mehr, desto..)

&lt;img src="lecture09_files/figure-html/unnamed-chunk-5-1.png" width="504" style="display: block; margin: auto;" /&gt;



---
# Varianz und Covarianz

$$ VAR(X) = \frac{1}{N} \sum_{i=1}^{N}{(x_i - \bar{x})^2} $$
Varianz ist die mittlere quadratische Abweichung vom Mittelwert.

--

Covarianz ist "mittlere" Abweichung zweier verbundener Variablen vom verbundenen Mittelwert.

`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{(x_{i} - \bar{x})(y_{i} - \bar{y})}$$`
---
# Einfaches Beispiel

2 Variablen: x, y

3 Werte: je 2,4,6

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; x &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; y &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;



---
# Visuelle Interpretation
`$$\bar{x}=$$`
`$$\bar{y}=$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-7-1.png" width="360" style="display: block; margin: auto;" /&gt;


---
# Visuelle Interpretation
$$\bar{x}=\frac{1}{3} (2+4+6) = 4 $$
`$$\bar{y}=$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-8-1.png" width="360" style="display: block; margin: auto;" /&gt;


---
# Visuelle Interpretation
$$\bar{x}=\frac{1}{3} (2+4+6) = 4 $$
`$$\bar{y}=$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-9-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Visuelle Interpretation
$$\bar{x}=\frac{1}{3} (2+4+6) = 4 $$
`$$\bar{y}=\frac{1}{3} (2+4+6) = 4$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-10-1.png" width="360" style="display: block; margin: auto;" /&gt;


---
# Visuelle Interpretation
$$\bar{x}= 4 $$
`$$\bar{y}= 4$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-11-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Visuelle Interpretation
`$$\bar{x}= 4 \text{ und } \bar{y}= 4$$`
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{(x_{i} - \bar{x})(y_{i} - \bar{y})}$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-12-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{2} \sum_{i=1}^{3}{(x_{i} - 4)(y_{i} - 4)}$$` 
--

`$$= \frac{1}{2}( (x_1-4)(y_1-4) + (x_2-4)(y_2-4) + (x_3-4)(y_3-4))$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-13-1.png" width="360" style="display: block; margin: auto;" /&gt;


---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}(y_{i} - \bar{y})}$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-14-1.png" width="360" style="display: block; margin: auto;" /&gt;
---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}(y_{i} - \bar{y})}$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-15-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}\color{blue}{(y_{i} - \bar{y})}}$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-16-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}\color{blue}{(y_{i} - \bar{y})}}$$`
$$ = \frac{1}{2}( \color{red}{-2} \cdot \color{blue}{-2} + \ldots = \frac{1}{2}( 4 + \ldots$$

&lt;img src="lecture09_files/figure-html/unnamed-chunk-17-1.png" width="360" style="display: block; margin: auto;" /&gt;


---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}\color{blue}{(y_{i} - \bar{y})}}$$`
$$ = \frac{1}{2}( \color{red}{-2} \cdot \color{blue}{-2} + 0 +\ldots = \frac{1}{2}( 4 + 0 + \ldots$$

&lt;img src="lecture09_files/figure-html/unnamed-chunk-18-1.png" width="360" style="display: block; margin: auto;" /&gt;


---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}\color{blue}{(y_{i} - \bar{y})}}$$`
$$ = \frac{1}{2}( \color{red}{-2} \cdot \color{blue}{-2} + 0 +\ldots = \frac{1}{2}( 4 + 0 + \ldots$$

&lt;img src="lecture09_files/figure-html/unnamed-chunk-19-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}\color{blue}{(y_{i} - \bar{y})}}$$`
$$ = \frac{1}{2}( \color{red}{-2} \cdot \color{blue}{-2} + 0 +\color{red}{2} \cdot \color{blue}{2} ) = \frac{1}{2}( 4 + 0 + 4) = \frac{8}{2} = 4$$

&lt;img src="lecture09_files/figure-html/unnamed-chunk-20-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Kann das R auch ?

```r
cov(df_pos$x, df_pos$y)
```

```
## [1] 4
```
---
# Einfaches Beispiel 2

2 Variablen: x, y

3 Werte: je 2,4,6

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; x &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; y &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
# Visuelle Interpretation
$$\bar{x}= 4 $$
`$$\bar{y}= 4$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-23-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}(y_{i} - \bar{y})}$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-24-1.png" width="360" style="display: block; margin: auto;" /&gt;



---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}(y_{i} - \bar{y})}$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-25-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}\color{blue}{(y_{i} - \bar{y})}}$$`

&lt;img src="lecture09_files/figure-html/unnamed-chunk-26-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}\color{blue}{(y_{i} - \bar{y})}}$$`
$$ = \frac{1}{2}( \color{red}{-2} \cdot \color{blue}{2} + \ldots = \frac{1}{2}( -4 + \ldots$$

&lt;img src="lecture09_files/figure-html/unnamed-chunk-27-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Visuelle Interpretation
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}\color{blue}{(y_{i} - \bar{y})}}$$`
$$ = \frac{1}{2}( \color{red}{-2} \cdot \color{blue}{2} + 0 +\color{red}{2} \cdot \color{blue}{2} ) = \frac{1}{2}( -4 + 0 + (-4)) = -\frac{8}{2} = -4$$

&lt;img src="lecture09_files/figure-html/unnamed-chunk-28-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Kann das R auch ?

```r
cov(df_pos$x, df_pos$y)
```

```
## [1] -4
```

---
# Was passiert bei Veränderung?
`$$COV_{xy} = \frac{1}{N-1} \sum_{i=1}^{N}{\color{red}{(x_{i} - \bar{x})}\color{blue}{(y_{i} - \bar{y})}}$$`
$$ = \frac{1}{2}( \color{red}{-2} \cdot \color{blue}{2} + 0 +\color{red}{2} \cdot \color{blue}{2} ) = \frac{1}{2}( -4 + 0 + (-4)) = -\frac{8}{2} = -4$$

&lt;img src="lecture09_files/figure-html/unnamed-chunk-30-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Covarianz ist beschreibt einen Zusammenhang
- positiv, wenn gilt: je mehr, desto mehr
- negativ, wenn gilt: je mehr, desto weniger

Die Covarianz hängt ab von der Streuung in beide Richtungen: 
- `\(VAR(X)\)`
- `\(VAR(Y))\)`
- Große Streuung =&gt; große Covarianz

---
# Beschreibung eines Zusammenhangs
- Covarianz (hängt von beiden Streuungen ab)
- Korrelation (rechnet die Streuung als Standardabwichung wieder raus)

--

$$ r = \frac{COV(XY)}{\sqrt{VAR(X)} \sqrt{VAR(Y)} } = \frac{COV(XY)}{SD(X) SD(Y)} $$


```r
cov(df_pos$x, df_pos$y)
```

```
## [1] -4
```

```r
sd(df_pos$x)
```

```
## [1] 2
```

```r
sd(df_pos$y)
```

```
## [1] 2
```
--


```r
cor(df_pos$x, df_pos$y)
```

```
## [1] -1
```

---
# Pearson Moment Korrelation
- wird mit `\(r\)` beschrieben
- `\(r\)` ist der Korrelationskoeffizient
- `\(r\)` liegt immer zwischen -1 und 1

Vorraussetzung:
- beide Variablen sind normalverteilt

--
![](figs/correlations.png)


---
# Hypothesentest mit R
.pull-left[
&lt;img src="lecture09_files/figure-html/unnamed-chunk-33-1.png" width="504" style="display: block; margin: auto;" /&gt;
]

--

.pull-right[

```r
cor.test(data=df_multi, 
         ~height+shoesize)
```

```
## 
## 	Pearson's product-moment correlation
## 
## data:  height and shoesize
## t = 0.41594, df = 98, p-value = 0.6784
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.1557230  0.2364477
## sample estimates:
##        cor 
## 0.04197917
```
 ]

Es gibt keinen signifikanten Zusammenhang zwischen Körpergröße und Schuhgröße ( `\(r(98)=.042, p=.678\)` ).

---
# Alternativen
## Was tun, wenn Daten nicht normalverteilt sind?
- Spearman Rangkorrelation: `\(\rho\)` (gr. rho)

--


```r
cor.test(data=df_multi, 
         ~height+shoesize, method="spearman")
```

```
## 
## 	Spearman's rank correlation rho
## 
## data:  height and shoesize
## S = 162300, p-value = 0.7967
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##        rho 
## 0.02608539
```

--

Es gibt keinen signifikanten Zusammenhang zwischen Schuhgröße und Körpergröße ( `\(\rho=0.03, p=.7967\)` ).

---
![](figs/spearman.png)

---
# Alternativen 2
## Was tun, wenn Daten nicht intervallskaliert sind?

--
- Kendall's tau Rangkorrelation: `\(\tau\)` 


--


```r
cor.test(data=df_multi, 
         ~height+round(shoesize), method="kendall")
```

```
## 
## 	Kendall's rank correlation tau
## 
## data:  height and round(shoesize)
## z = 0.18183, p-value = 0.8557
## alternative hypothesis: true tau is not equal to 0
## sample estimates:
##        tau 
## 0.01324508
```

--

Es gibt keinen signifikanten Zusammenhang zwischen Schuhgröße und Körpergröße ( `\(\tau=0.01, p=.8557\)` ).

---
# Zusammenfassung
- Korrelation zum Beschreiben und Testen von Zusammenhängen
- Korrelationskoeffizient beschreibt "Stärke" des Zusammenhangs ( `\(r \in [-1;1]\)`)
- Je nach Vorraussetzung, unterschiedliche Verfahren.

## Korrelationstabelle


```
## 
##  CORRELATION MATRIX
## 
##  Correlation Matrix                                                
##  ───────────────────────────────────────────────────────────────── 
##                                robo_bed    robo_food    robo_med   
##  ───────────────────────────────────────────────────────────────── 
##    robo_bed     Pearson's r           —                            
##                 p-value               —                            
##                                                                    
##    robo_food    Pearson's r       0.556            —               
##                 p-value          &lt; .001            —               
##                                                                    
##    robo_med     Pearson's r       0.502        0.519           —   
##                 p-value          &lt; .001       &lt; .001           —   
##  ─────────────────────────────────────────────────────────────────
```

---
class: inverse, center, middle
## .yellow[Korrelationen können nicht für die Vorhersage genutzt werden.]


---
# Vorhersage von Zusammenhängen

## Terminologie
- abhängige Variable: Zielvariable, soll vorhergesagt werden
- unabhägnige Variable, Prädiktor: Eingangsvariable, die für die Vorhersage verwendet werden soll.

--

## Lineares Modell
- Wir beschreiben typischer weise "lineare" Zusammenhänge
- Je mehr `\(a\)`, desto mehr `\(b\)`.

--

Beispiel:

- Je größer die Person, desto größer die Füße.
- Pro cm Körpergröße, erwarten wir mit x cm Fußlänge.

---
# Lineares Modell

## Lineare Gleichung
$$ y = b \cdot x + b_0 + \epsilon $$
- `\(y\)` = abhängige Variable (hier: Fußlänge)
- `\(x\)` = unabhängige Variable (hier: Körpergröße)
- `\(b, b_0\)` = Koeffizienten (slope)
- `\(b_0\)` = Intercept (y-Achsenabschnitt)
- `\(\epsilon\)` = Fehlerterm 

---
# Beispiel:

$$ y = 0.75 \cdot x + 1 + \epsilon $$

&lt;img src="lecture09_files/figure-html/unnamed-chunk-38-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Vorhersage von Daten mit linearer Regression

&lt;img src="lecture09_files/figure-html/unnamed-chunk-39-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Vorhersage von Daten mit linearer Regression
&lt;img src="lecture09_files/figure-html/unnamed-chunk-40-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Vorhersage von Daten mit linearer Regression

&lt;img src="lecture09_files/figure-html/unnamed-chunk-41-1.png" width="504" style="display: block; margin: auto;" /&gt;


---
# Vorhersage von Daten mit linearer Regression

&lt;img src="lecture09_files/figure-html/unnamed-chunk-42-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Vorhersage von Daten mit linearer Regression

&lt;img src="lecture09_files/figure-html/unnamed-chunk-43-1.png" width="504" style="display: block; margin: auto;" /&gt;

---
# Vorhersage von Daten mit linearer Regression

&lt;img src="lecture09_files/figure-html/unnamed-chunk-44-1.png" width="504" style="display: block; margin: auto;" /&gt;



---
# Vorhersage von Daten mit linearer Regression

&lt;img src="lecture09_files/figure-html/unnamed-chunk-45-1.png" width="504" style="display: block; margin: auto;" /&gt;


---
# Lineare Regression in R
&lt;pre style="font-size:8pt"&gt;

```r
df &lt;- hcictools::robot_care
jmv::linReg(df, dep = c("robo_bed"), covs = c("kut"), blocks = list("kut"), r2Adj = T, stdEst = T, anova=T)
```

```
## 
##  LINEAR REGRESSION
## 
##  Model Fit Measures                          
##  ─────────────────────────────────────────── 
##    Model    R        R²        Adjusted R²   
##  ─────────────────────────────────────────── 
##        1    0.261    0.0682         0.0650   
##  ─────────────────────────────────────────── 
## 
## 
##  MODEL SPECIFIC RESULTS
## 
##  MODEL 1
## 
##  Omnibus ANOVA Test                                                      
##  ─────────────────────────────────────────────────────────────────────── 
##                 Sum of Squares    df     Mean Square    F       p        
##  ─────────────────────────────────────────────────────────────────────── 
##    kut                    33.5      1          33.52    21.3    &lt; .001   
##    Residuals             457.8    291           1.57                     
##  ─────────────────────────────────────────────────────────────────────── 
##    Note. Type 3 sum of squares
## 
## 
##  Model Coefficients - robo_bed                                             
##  ───────────────────────────────────────────────────────────────────────── 
##    Predictor    Estimate    SE        t        p         Stand. Estimate   
##  ───────────────────────────────────────────────────────────────────────── 
##    Intercept       3.319    0.3181    10.43    &lt; .001                      
##    kut             0.331    0.0716     4.62    &lt; .001              0.261   
##  ─────────────────────────────────────────────────────────────────────────
```
&lt;/pre&gt;

---
# Bericht

Die lineare Regression zeigt, dass ein Modell mit einem Prädiktor ( `\(F(1,291)=21.3, p&lt;.001, \text{adj.} r^2 = 0.065\)` , siehe Tabelle 1) signifikant wird. Das Modell klärt somit 6,5% mehr Varianz auf, als der Mittelwert alleine. Ob sich jemand von einem Roboter ins Bett bringen möchte, kann mit folgender Formel vorhergesagt werden: `\(\text{robo_bed} = 3.319 + 0.331 \cdot \text{kut}\)` .

Tabelle 1: Tabelle der linearen Regression robo_bed ~ kut

| Prädiktor  |  Koeff. B |   SE     |   t     |   p       |  Stand. Koeff. `\(\beta\)`     |
|:-----------|----------:|---------:|--------:|----------:|---------------------:|
| Interzept  |     3.319 |   0.3181 |   10.43 |   &lt; .001  |                      |
| kut        |     0.331 |   0.0716 |    4.62 |   &lt; .001  |            0.261     |



---
# Vorteile der linearen Regression
- Vorhersage eines Parameters durch einen (oder mehrere) andere
- Mehrere Parameter: Multiple Regression

Vorraussetzungen:
- Intervallskalierte Daten, insbesondere die abhängige Variable
- Normalverteilte Fehler 
- Homoskedastizität (Gleichheit der Fehler über die Wertebereiche aller Prädiktoren)

.pull-left[
Heteroskedastizität
![](figs/heteroske.jpg)
]

---
# Andere Probleme

![](figs/error1.png)

---
# Andere Probleme

![](figs/error2.png)


---
# Multiple lineare Regression
```r
jmv::linReg(df, dep = c("robo_bed"), covs = c("kut", "age"), 
             blocks = list("kut", "age"), r2Adj = T, stdEst = T, anova=T)
```

&lt;!--pre style="font-size:6pt" --&gt;

```
## 
##  MODEL 1
## 
##  Omnibus ANOVA Test                                                      
##  ─────────────────────────────────────────────────────────────────────── 
##                 Sum of Squares    df     Mean Square    F       p        
##  ─────────────────────────────────────────────────────────────────────── 
##    kut                    33.5      1          33.52    21.3    &lt; .001   
##    Residuals             457.8    291           1.57                     
##  ─────────────────────────────────────────────────────────────────────── 
##    Note. Type 3 sum of squares
## 
## 
##  Model Coefficients - robo_bed                                             
##  ───────────────────────────────────────────────────────────────────────── 
##    Predictor    Estimate    SE        t        p         Stand. Estimate   
##  ───────────────────────────────────────────────────────────────────────── 
##    Intercept       3.319    0.3181    10.43    &lt; .001                      
##    kut             0.331    0.0716     4.62    &lt; .001              0.261   
##  ─────────────────────────────────────────────────────────────────────────
```
&lt;!--/pre--&gt;


---
# Multiple lineare Regression
```r
jmv::linReg(df, dep = c("robo_bed"), covs = c("kut", "age"), 
             blocks = list("kut", "age"), r2Adj = T, stdEst = T, anova=T)
```


```
## 
##  MODEL 2
## 
##  Omnibus ANOVA Test                                                         
##  ────────────────────────────────────────────────────────────────────────── 
##                 Sum of Squares    df     Mean Square    F          p        
##  ────────────────────────────────────────────────────────────────────────── 
##    kut                 31.0811      1        31.0811    19.6913    &lt; .001   
##    age                  0.0462      1         0.0462     0.0292     0.864   
##    Residuals          457.7410    290         1.5784                        
##  ────────────────────────────────────────────────────────────────────────── 
##    Note. Type 3 sum of squares
## 
## 
##  Model Coefficients - robo_bed                                              
##  ────────────────────────────────────────────────────────────────────────── 
##    Predictor    Estimate    SE         t        p         Stand. Estimate   
##  ────────────────────────────────────────────────────────────────────────── 
##    Intercept       3.270    0.42580    7.680    &lt; .001                      
##    kut             0.334    0.07537    4.437    &lt; .001             0.2643   
##    age           9.75e-4    0.00570    0.171     0.864             0.0102   
##  ──────────────────────────────────────────────────────────────────────────
```



---
# Multiple lineare Regression

```
## 
##  Model Fit Measures                          
##  ─────────────────────────────────────────── 
##    Model    R        R²        Adjusted R²   
##  ─────────────────────────────────────────── 
##        1    0.261    0.0682         0.0650   
##        2    0.261    0.0683         0.0619   
##  ───────────────────────────────────────────
```

```
## 
##  Model Comparisons                                                   
##  ─────────────────────────────────────────────────────────────────── 
##    Model         Model    ΔR²        F         df1    df2    p       
##  ─────────────────────────────────────────────────────────────────── 
##        1    -        2    9.40e-5    0.0292      1    290    0.864   
##  ───────────────────────────────────────────────────────────────────
```


---
# Zusammenfassung

Zusammenhangshypothesen können mit Korrelation und linearer Regression untersucht werden.
- Korrelation misst nur die Stärke und Richtung: Korrelationskoeffizient
- Lineare Regression trifft eine Vorhersage: Lineare Gleichung
- Lineare Regression kann einfach auf mehrere Variablen erweitert werden.

---
# Übersicht

1. .gray[Was sind Methoden?] =&gt; [Link](lecture01.html) `\(\checkmark\)`
2. .gray[Qualitative und Quantitative Daten? Forschungsfrage wählen] =&gt; [Link](lecture02.html) `\(\checkmark\)`
3. .gray[Wissenschaftstheorie, Empirie und Theorie] =&gt; [Link](lecture03.html) `\(\checkmark\)`
4. .gray[Forschungsintstrument entwickeln, Messtheorie, Skalenniveaus] =&gt; [Link](lecture04.html) `\(\checkmark\)`
5. .gray[Deskriptive Statistik, zentrale Tendenz und Streuung] =&gt; [Link](lecture05.html) `\(\checkmark\)`
6. .gray[Verteilungen, Stichproben und Wahrscheinlichkeit] =&gt; [Link](lecture06.html) `\(\checkmark\)`
7. .gray[Inferenz, Hypothesen, Fehler 1. und 2. Art, t-Test] =&gt; [Link](lecture07.html) `\(\checkmark\)`
8. Alpha-Fehler Kummulierung, ANOVA, MANOVA, Bonferroni =&gt; [Link](lecture08.html) `\(\checkmark\)`
9. Zusammenhänge, Korrelation, lineare Regression =&gt; [Link](lecture09.html)
10. Skalen, Likert-Skalen, Reliabilität und Faktoren-Analyse =&gt; [Link](lecture10.html)
11. Explorative Statistik, parametrische und nicht-parametrische Verfahren =&gt; [Link](lecture11.html)
12. Conjoint-Verfahren, Cluster-Analyse =&gt; [Link](lecture12.html)
13. Effekt-Stärken und Poweranalyse =&gt; [Link](lecture13.html)
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
